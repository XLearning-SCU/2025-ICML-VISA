# 服务器名字

服务器：titan
账号：guofeng@192.168.50.160
密码：1q2w3e

服务器：A10
账号：guofeng@192.168.49.48
密码：1q2w3e

服务器：3090-1

账号：guofeng@192.168.49.44
密码：1q2w3e

服务器：3090-2
账号：guofeng@192.168.49.47
密码：1q2w3e

服务器：3090-3
账号：guofeng@192.168.49.56
密码：1q2w3e

服务器：3090-4
账号：guofeng@192.168.49.52
密码：1q2w3e

服务器：3090-5
账号：guofeng@192.168.49.58
密码：1q2w3e

服务器：4090-1
账号：guofeng@192.168.49.59
密码：1q2w3e



# nvitop

```
nvitop -m compact --interval 1 --user boyun yuanbiao mouxing yijie yunfan haobin yiding haiyu honglin ruiming ruohong guofeng guokai root haochen
```



# 开启llava和qwen

- 在4090-1上开启llava-34b

```python
CUDA_VISIBLE_DEVICES=4,5,6,7 HF_ENDPOINT=https://hf-mirror.com /data/yiding/anaconda3/envs/sglang/bin/python -m sglang.launch_server --model-path /data/yiding/models/llava-v1.6/llava-v1.6-34b --tp-size=4 --chat-template=chatml-llava --tokenizer-path /data/yiding/models/llava-v1.6/llava-v1.6-34b-tokenizer/ --mem-fraction-static 0.8 --host "0.0.0.0" --port=11111
```

- 在4090-1上开启qwen2.5-32B

```python
CUDA_VISIBLE_DEVICES=4,5,6,7 /data/yiding/anaconda3/envs/sglang/bin/python -m sglang.launch_server --model-path /data/guofeng/test/DL/data/model/Qwen2.5/Qwen2.5-32B-Instruct --tp 4 --enable-p2p-check --mem-fraction-static 0.8 --host "0.0.0.0" --disable-cuda-graph --port 22222 
```



- 在3090-4上开启qwen2.5-72B

```python
CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 /data/guofeng/anaconda3/envs/sglang/bin/python -m sglang.launch_server --model-path /data/guofeng/test/DL/data/model/Qwen2.5/Qwen2.5-72B-Instruct --tp 8 --enable-p2p-check --mem-fraction-static 0.8 --host "0.0.0.0" --disable-cuda-graph --port 44444
```



- 在3090-3上开启llava-34b

```python
CUDA_VISIBLE_DEVICES=0,1,2,3 /hdd/guofeng/anaconda3/envs/sglang/bin/python -m sglang.launch_server --model-path /hdd/guofeng/test/DL/data/model/llava-v1.6-34b --tp-size=4 --chat-template=chatml-llava --tokenizer-path /hdd/guofeng/test/DL/data/model/llava-v1.6-34b-tokenizer --mem-fraction-static 0.8 --host "0.0.0.0" --disable-cuda-graph --port=33333
```

- 在3090-3上开启llava-7b

```python
HF_ENDPOINT=https://hf-mirror.com CUDA_VISIBLE_DEVICES=0 /hdd/guofeng/anaconda3/envs/sglang/bin/python -m sglang.launch_server --model-path /hdd/guofeng/test/DL/data/model/llava-v1.6-mistral-7b-sglang --tp-size=1 --chat-template=vicuna_v1.1 --mem-fraction-static 0.8 --host "0.0.0.0" --disable-cuda-graph --port=1031
```

- 在3090-3上开启qwen2.5-32B

```python
CUDA_VISIBLE_DEVICES=0,1,2,3 /hdd/guofeng/anaconda3/envs/sglang/bin/python -m sglang.launch_server --model-path /hdd/guofeng/test/DL/data/model/Qwen2.5/Qwen2.5-32B-Instruct --tp 4 --enable-p2p-check --mem-fraction-static 0.8 --host "0.0.0.0" --disable-cuda-graph --port 44444
```

- 在3090-3上开启qwen2.5-72B

```
CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 /hdd/guofeng/anaconda3/envs/sglang/bin/python -m sglang.launch_server --model-path /hdd/guofeng/test/DL/data/model/Qwen2.5/Qwen2.5-72B-Instruct --tp 8 --enable-p2p-check --mem-fraction-static 0.8 --host "0.0.0.0" --disable-cuda-graph --port 44444
```

- 在3090-3上开启qwen2-VL

```
CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 /hdd/guofeng/anaconda3/envs/sglang/bin/python -m sglang.launch_server --model-path /hdd/guofeng/test/DL/data/model/Qwen2-VL/Qwen2-VL-72B-Instruct --tp 8 --enable-p2p-check --chat-template qwen2-vl --mem-fraction-static 0.8 --host "0.0.0.0" --disable-cuda-graph --port 44444



下面这个是对的
CUDA_VISIBLE_DEVICES=0 /hdd/guofeng/anaconda3/envs/sglang/bin/python -m sglang.launch_server --model-path /hdd/guofeng/test/DL/data/model/Qwen2-VL/Qwen2-VL-7B-Instruct --host "0.0.0.0" --chat-template qwen2-vl --disable-cuda-graph --tp 1 --port 11111


CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 /hdd/guofeng/anaconda3/envs/sglang/bin/python -m sglang.launch_server --model-path /hdd/guofeng/test/DL/data/model/Qwen2-VL/Qwen2-VL-72B-Instruct --host "0.0.0.0" --chat-template qwen2-vl --disable-cuda-graph --tp 8 --port 11111
```

- 3090-2开启开启qwen2.5-32B

```
CUDA_VISIBLE_DEVICES=3,4,5,6 /xlearning/guofeng/anaconda3/envs/sglang/bin/python -m sglang.launch_server --model-path /xlearning/guofeng/test/DL/data/model/Qwen2.5/Qwen2.5-32B-Instruct --tp 4 --enable-p2p-check --mem-fraction-static 0.8 --host "0.0.0.0" --disable-cuda-graph --port 44444
```

- 3090-1开启llava-34B

```
CUDA_VISIBLE_DEVICES=0,1,2,3 /xlearning/guofeng/anaconda3/envs/sglang/bin/python -m sglang.launch_server --model-path /xlearning/guofeng/test/DL/data/model/llava-v1.6-34b --tp-size=4 --chat-template=chatml-llava --tokenizer-path /xlearning/guofeng/test/DL/data/model/llava-v1.6-34b-tokenizer --mem-fraction-static 0.8 --host "0.0.0.0" --disable-cuda-graph --port=33333
```



- LLaVA-NeXT-Video-32B-Qwen，配环境要用inference这个分支

```
https://github.com/LLaVA-VL/LLaVA-NeXT/tree/inference
需要用到以下环境
flash_attn-2.6.3+cu123torch2.1cxx11abiFALSE-cp310-cp310-linux_x86_64.whl
pip install opencv-python
pip install numpy==1.24.3
pip install transformers==4.39.3
pip install openai


bash /data/guofeng/test/DL/github/LLaVA-NeXT-inference/scripts/video/demo/LSMDC_test1000.sh /data/guofeng/test/DL/data/model/LLaVA-NeXT-Video-32B-Qwen qwen_1_5 32 2 average after grid True  /data/guofeng/test/demo_12s.mp4
```



# tmux

> control+B+S：切换tmux会话
>
> control+B，松开，再按'['这个建：向上划tmux。再按esc退出
>
> ctrl+b+: +输入rename-session new_name
>

# flash-attention

https://github.com/Dao-AILab/flash-attention/releases

# 空占内存

> fuser -v /dev/nvidia6

# 环境

> 新建环境：conda create -n name
>
> 删除环境：conda remove --name name --all

# OMP_NUM_THREADSw

```
OMP_NUM_THREADS=4
```

# 解压zip

```
unzip filename.zip -d /path/to/destination
```

# df用来查看磁盘空间的使用情况

```
df -h
```

# 看某个文件或者文件夹的大小

```
du -sh /draft.py
du -sh /folder
```

# 安装sglang

- 1、conda env create -f env.yaml
- 2、pip install flashinfer-0.1.6+cu121torch2.4-cp310-cp310-linux_x86_64.whl
- 3、pip install "sglang[all]"
- 4、flash_attn-2.6.3+cu118torch2.4cxx11abiFALSE-cp310-cp310-linux_x86_64.whl

# 从服务器传文件到百度网盘

传到百度网盘的路径是：我的应用数据/bypy/guofeng

```python
bypy upload your_file guofeng -v
```

# 找某个文件夹下面是不是有某个文件

```python
find /data/guofeng/test/DL -iname "namelongcap_scores0-1-3_llava7b.pkl"
```

# 压缩文件夹

```python
zip -r my_folder.zip my_folder
```

# 加清华源

```
-i https://pypi.tuna.tsinghua.edu.cn/simple
```

# autodl

```
ssh -p 57604 root@connect.bjc1.seetacloud.com

Gv3FMI1tna5M
```

pycharm ssh

- 主机：connect.bjc1.seetacloud.com
- 端口：57604
- 用户名：root
- 密码：Gv3FMI1tna5M
- 系统盘：/root/**autodl**-pub
- 数据盘：/root/**autodl**-tmp

```
scp -r -P 57604 your_file root@connect.bjc1.seetacloud.com:/root/autodl-tmp
```

# 安装qwenvl2.5

```
 git clone --depth 1 https://ghfast.top/https%3A//github.com/huggingface/transformers
 
 cd transformers
 
 pip install .
```

# 能运行qwenvl的flash-attn

```
flash_attn-2.6.3+cu118torch2.3cxx11abiFALSE-cp311-cp311-linux_x86_64.whl
```

# 用os打印path

```py
import os
print(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))  # 上一级目录
print(os.path.dirname(os.path.abspath(__file__)))  # 当前文件所在的目录（绝对路径）
print(os.path.abspath(__file__)) # 当前文件的完整路径
print(os.path.basename(os.path.abspath(__file__))) # 当前文件名


/hdd/guofeng
/hdd/guofeng/test
/hdd/guofeng/test/draft.py
draft.py
```

# 打包环境

```python
conda info --envs

tar -czvf sglang_env.tar.gz -C /hdd/guofeng/anaconda3/envs sglang

tar -xzvf /xlearning/guofeng/test/sglang_env.tar.gz -C /xlearning/guofeng/anaconda3/envs
```

# 压缩

```python
/home/user/my_folder/
└── file1.txt
└── subdir/

tar -czf archive_name.tar.gz -C my_folder .


最终压缩包 archive_name.tar.gz 中只包含 file1.txt、subdir/，没有 my_folder/ 这一层
```

# 解压缩

```python
tar -xzf archive_name.tar.gz
```

